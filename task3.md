# CHANNELS
## Задание: Анализ и исправление кода с гонками данных

### Описание задачи
1. Внимательно изучить код.
2. Найти все ошибки, описать их в комментариях прямо в коде.
3. Исправить код, обеспечив корректную работу.

```go
package main

import (
	"fmt"
	"math/rand"
	"sync"
)

func main() {
	alreadyStored := make(map[int]struct{})
	storeMu := sync.Mutex{} 
	
	capacity := 1000
	doubles := make([]int, 0, capacity)
	for i := 0; i < capacity; i++ {
		doubles = append(doubles, rand.Intn(10))
	}
	uniqueIDs := make(chan int, capacity)
	wg := sync.WaitGroup{}
	for i := 0; i < capacity; i++ {
		// i := i стоит выбрать другое название для переменной или передавать как аргумент
		
		wg.Add(1)
		go func(ind int) {
			defer wg.Done()
			
			storeMu.Lock() // используем мьютекст для конкурентного доступа к мапе
			defer storeMu.Unlock()	
			
			if _, ok := alreadyStored[doubles[ind]]; !ok {
				alreadyStored[doubles[ind]] = struct{}{}
				uniqueIDs <- doubles[ind]
			}
		}(i) // копируем через аргумент в функцию 
	}
	wg.Wait()
	close(uniqueIDs) // закрываем канал, иначе дедлок в цикле
	for val := range uniqueIDs {
		fmt.Println(val)
	}
	fmt.Println(uniqueIDs)
}
```
---
## Задание: Анализ времени выполнения параллельных операций в Go

**Цель задания**:  
Понять, как работают горутины и каналы в Go, определить время выполнения программы и исправить код для достижения ожидаемого результата.

---

### Описание задачи

Данная программа создает два параллельных "воркера", каждый из которых через 3 секунды отправляет число в канал. 
Задача:
1. Определить, какое число выведет программа (сколько секунд она будет выполняться).
2. Объяснить, почему результат получился именно таким.
3. Исправить код (если необходимо), чтобы время выполнения составило **ровно 3 секунды**.
```go
package main

import (
	"time"
)

func worker() chan int {
	ch := make(chan int)
	go func() {
		time.Sleep(3 * time.Second)
		ch <- 42
	}()
	return ch
}
func main() {
	timeStart := time.Now()
// Синхронно присваиваем значения. Запускаем последовательно воркеры и сразу лочимся на возвращаемом канале, переходим к следующему только после получения предыдущего значения
//	_, _ = <-worker(), <-worker() 

	//фикс: сначала получаем каналы, затем читаем из них
	ch1, ch2 := worker(), worker()
	_,_ = <-ch1, <-ch2
	println(int(time.Since(timeStart).Seconds()))
}
```
---
## Задание: Конвейер чисел на Go

**Цель задания**:  
Реализовать конвейер для обработки чисел с использованием горутин и каналов. Числа из первого канала должны читаться по мере поступления, обрабатываться (например, возводиться в квадрат) и записываться во второй канал.

---

### Описание задачи

Даны два канала:
- `naturals` (для передачи исходных чисел),
- `squares` (для передачи обработанных чисел).

Необходимо:
1. **Генерировать** числа и отправлять их в канал `naturals`.
2. **Читать** числа из `naturals`, обрабатывать их (возводить в квадрат) и отправлять результат в `squares`.
3. **Выводить** результаты из `squares` в консоль.

```
Решение в ./conveyor
```
---
## Задание: Объединение каналов в Go

**Цель задания**:  
Написать функцию `mergeChannels`, которая объединяет данные из нескольких каналов в один общий канал, используя паттерн `FAN-IN`.

---

### Описание задачи

Дано:
- `n` каналов типа `<-chan int`.
- Функция должна вернуть канал `<-chan int`, в который попадают все значения из исходных каналов.

Требования:
1. Все значения из входных каналов должны быть отправлены в выходной канал.
2. Выходной канал должен быть закрыт после завершения всех входных каналов.
3. Решение должно быть потокобезопасным и эффективным.

```
Решение в ./merge
```
---


## Задание: Параллельный подсчет слов в файлах с использованием паттерна Fan-Out

### Цель задания
Реализовать параллельную обработку текстовых файлов с использованием паттерна **Fan-Out**, чтобы ускорить подсчет слов в каждом файле.

### Описание задачи
Есть директория с текстовыми файлами. Нужно:
1. Прочитать все файлы.
2. Распределить их обработку между несколькими горутинами.
3. Подсчитать количество слов в каждом файле.
4. Вывести общую статистику.

### Требования
- Использовать паттерн **Fan-Out** для распределения задач.
- Обработка каждого файла должна выполняться в отдельной горутине.
- Результаты должны агрегироваться в основном потоке.

```
Решение в ./filewords
```



## Задание: Реализация паттерна "Tee" для записи в несколько реплик БД

**Цель задания**:  
Реализовать паттерн "Разветвитель", при котором данные из одного источника параллельно записываются в несколько реплик базы данных (имитированных каналами).

---

### Описание задачи

Есть сервис, который записывает данные в кластер БД, состоящий из нескольких реплик. Требуется:
1. Принимать данные из входного канала.
2. Параллельно отправлять их во все реплики (каналы).
3. Гарантировать, что данные записаны во все реплики.
4. Корректно закрыть реплики после завершения работы.

```
Решение в ./tee
```


---
## Задание: Реализация декоратора для преобразования метрик в реальном времени

**Цель задания**:  


Создать гибкий декоратор для каналов, который будет автоматически преобразовывать метрики серверов из байтов в мегабайты перед отправкой в API. Используя паттерн `TRANSFORMER`


### Описание задачи

В системе мониторинга серверов:
1. **Источник данных**: Канал `metrics <-chan ServerMetric` получает метрики в формате:
   ```go
   type ServerMetric struct {
       Name  string  // Название метрики (например, "memory_usage")
       Value float64 // Значение в байтах
   }
   ```

```
Решение в ./transformer
```

# Задание: Реализация конвейерной обработки данных (Pipeline паттерн)

**Цель задания**:  
Создать конвейер из трех этапов для обработки строковых данных:
1. **Парсинг** — добавление метки "parsed" к данным.
2. **Разделение** — распределение данных между N каналами (round-robin).
3. **Отправка** — параллельная обработка данных в N горутинах с добавлением метки "sent".

## Описание задачи

Ваша задача — реализовать систему, которая:
- Обрабатывает данные в строгом порядке: **Parse → Split → Send**.
- Корректно закрывает все каналы после завершения работы.
- Гарантирует потокобезопасность и отсутствие утечек горутин.

### Этапы конвейера

1. **Parse**:
   - Принимает канал сырых данных (`<-chan string`).
   - Добавляет к каждой строке префикс "parsed - ".
   - Возвращает канал обработанных данных.

2. **Split**:
   - Принимает канал данных и число `N` (количество выходных каналов).
   - Распределяет данные между `N` каналами в порядке round-robin.
   - Возвращает слайс каналов (`[]<-chan string`).

3. **Send**:
   - Принимает слайс каналов и запускает `N` горутин.
   - Каждая горутина добавляет к данным префикс "sent - ".
   - Возвращает объединенный канал результатов.
Но если что мы с тобой и так пройдем эти темы. А если хочешь прям догнать,то вот ресурсы и пиши по вопросам. Можем отдельно встречу организовать по вопросам:
https://www.youtube.com/watch?v=luQlkud-jKE&t=5s
https://habr.com/ru/companies/pt/articles/764850/

```
Решение в ./pipeline
```
--------------------------------------------
# CONCURRENCY
## Реализация потокобезопасного кеша 

### Описание задачи
Ваша задача — реализовать потокобезопасный кеш для хранения данных в формате ключ-значение. Кеш должен безопасно обрабатывать одновременные операции записи и чтения из множества горутин.

### Требования
1. Реализовать структуру `SafeCache` с методами:
   - `Set(key string, value string)` — добавляет значение в кеш.
   - `Get(key string) (string, bool)` — возвращает значение по ключу.
2. Гарантировать отсутствие data race при параллельном доступе.

```
Решение в ./safecache
```



# Параллельная загрузка данных из нескольких источников
---
## Описание задачи
Реализовать систему параллельной загрузки данных из независимых источников:
1. Асинхронная загрузка комментариев из БД
2. Параллельная загрузка данных пользователей на основе полученных комментариев
3. Загрузка данных сессии и условная загрузка вложений

**Цель:**   
Освоить работу с горутинами, `sync.Once` и синхронизацией через `sync.WaitGroup`.

---
## Требования
1. Загрузка комментариев и данных сессии должна выполняться параллельно
2. Загрузка данных пользователей должна стартовать только после получения комментариев
3. Загрузка вложений должна выполняться только при наличии session-id
4. Использовать минимум 3 горутины для разных этапов
5. Синхронизировать все операции перед завершением
Но если что мы с тобой и так пройдем эти темы. А если хочешь прям догнать,то вот дополнительные ресурсы. Можем отдельно встречу организовать по вопросам::
https://victoriametrics.com/blog/go-sync-once/

```
Решение в ./dataload
```
-----------------------------------------

# SYNC/COND
## Реализация очереди с ограниченной емкостью на sync.Cond

### Описание задачи
В распределенных системах часто требуется синхронизировать работу продюсеров (добавляющих задачи) и консьюмеров (обрабатывающих задачи). Очередь с фиксированной емкостью (`BoundedQueue`) решает следующие проблемы:
- **Блокировка продюсеров** при заполнении очереди.
- **Блокировка консьюмеров** при опустошении очереди.
- **Потокобезопасность** в многогоруточной среде.
- **Корректное завершение** работы через `Shutdown()`.

**Цель:**  
Реализовать очередь, использующую `sync.Cond` для эффективной синхронизации горутин.
### Требования
1. Реализация методов:
    - `Put(task interface{})` — блокируется, если очередь заполнена.
    - `Get() interface{}` — блокируется, если очередь пуста.
    - `Shutdown()` — завершает работу очереди.
2. Использование `sync.Cond` и `sync.Mutex` для синхронизации.
3. Гарантия отсутствия гонок и утечек.

```
Решение в ./cond/queue.go
```

## Моделирование работы ресторана с использованием `sync.Cond`

### Описание задачи
Реализовать систему управления столиками в ресторане, где:
- Количество столиков фиксировано (например, 5).
- Посетители (горутины) занимают столики, если они свободны.
- Если все столики заняты, посетители ожидают в очереди.
- При освобождении столика его получает первый ожидающий посетитель.

**Цель:**  
Научиться синхронизировать горутины с помощью `sync.Cond`, моделируя реальный сценарий с ограниченными ресурсами.

---

### Требования
1. Реализовать структуру `Restaurant` с методами:
    - `OccupyTable()` — блокируется, если нет свободных столиков.
    - `ReleaseTable()` — освобождает столик и уведомляет ожидающих.
2. Использовать `sync.Cond` для управления очередью ожидания.

```
Решение в ./cond/restaurant.go
```


## Пул подключений к БД с использованием `sync.Cond`

### Описание задачи
Реализовать пул подключений к базе данных с ограничением на максимальное количество активных подключений. Если все подключения заняты, новые запросы должны блокироваться до освобождения ресурсов. Использовать `sync.Cond` для синхронизации.

---

### Требования
1. Реализовать методы:
    - `Get() *Connection` — возвращает свободное подключение или блокирует горутину.
    - `Release(*Connection)` — освобождает подключение и уведомляет ожидающих.
2. Ограничить максимальное количество подключений (например, 3).
3. Гарантировать потокобезопасность.
4. Смоделировать работу с задержками (имитация запросов к БД).

---

```go
func main() {
    pool := NewConnectionPool(3) // Пул на 3 подключения

    for i := 0; i < 10; i++ {
        go func(id int) {
            conn := pool.Get()
            defer pool.Release(conn)

            fmt.Printf("Горутина %d: подключение %d получено\n", id, conn.ID)
            time.Sleep(2 * time.Second) // Имитация работы
        }(i)
    }

    time.Sleep(10 * time.Second)
}

```
Но если что мы с тобой и так пройдем эти темы. А если хочешь прям догнать,то вот дополнительные ресурсы. Можем отдельно встречу организовать по вопросам::
https://ubiklab.net/posts/go-sync-cond/
https://dev.to/func25/go-synccond-the-most-overlooked-sync-mechanism-1fgd
https://wcademy.ru/go-multithreading-sync-cond/

```
Решение в ./connectpool
```
-----------------------------------------

# SYNC/ONCE
## Задание: Ленивая инициализация подключения к базе данных с использованием `sync.Once`

**Цель задания**:  
Реализовать потокобезопасный механизм однократной инициализации подключения к базе данных с помощью `sync.Once`.

### Описание задачи

При работе с базами данных в многопоточной среде важно, чтобы подключение инициализировалось только один раз, даже если метод запроса подключения вызывается из нескольких горутин одновременно. В этом задании вам предстоит реализовать такую логику.

### Требования:
1. Создайте структуру `Database`, которая хранит подключение к БД (`conn`) и экземпляр `sync.Once`.
2. Реализуйте метод `GetConnection()`, который:
    - Инициализирует подключение к БД только при первом вызове.
    - Гарантирует, что последующие вызовы возвращают уже созданное подключение.
3. Убедитесь, что код потокобезопасен (нет гонок данных).


```
Решение в ./once/dbconnect.go
```

## Конфигуратор приложения с `sync.Once`

**Описание**
Этот проект реализует **потокобезопасный** менеджер конфигурации, который загружает настройки **только один раз** при первом запросе.  
Используется `sync.Once`, чтобы избежать повторной загрузки при одновременном доступе из нескольких горутин.
---

**Возможности**
1. Ленивая инициализация – загрузка конфигурации только при первом вызове.  
2. Потокобезопасность – отсутствие гонок данных при многопоточной работе.  
3. Гибкость – возможность загружать конфигурацию из файла, переменных окружения или базы данных.
---

**Реализованные методы**
- `LoadConfig()` – загружает конфигурацию **один раз** и сохраняет в памяти.
- `Get(key string) string` – возвращает значение конфигурации по ключу.
- `PrintConfig()` – выводит загруженные параметры.
---

```go
// Имитация загрузки конфигурации
cm.config = map[string]string{
"app_name":  "MyApp",
"port":      "8080",
"log_level": "debug",
}

func main() {
    keys := []string{"app_name", "port", "log_level"}
    configManager.PrintConfig()
}
```



```
Решение в ./configmanager
```

## Инициализация плагинов с `sync.Once`

**Цель задания**
Реализовать систему безопасной инициализации плагинов, где:
- Каждый плагин инициализируется **только один раз**
- Инициализация потокобезопасна
- Ошибки при инициализации корректно обрабатываются
- Плагины доступны для использования из разных компонентов
---

**Требования**
1. **Структура `PluginManager`**:
    - Хранит загруженные плагины
    - Использует `sync.Once` для каждого плагина
    - Поддерживает конкурентный доступ

2. **Методы**:
    - `GetPlugin(name string) (Plugin, error)` – возвращает инициализированный плагин
    - `RegisterPlugin()` – регистрирует плагины (симуляция)

```
Решение в ./pluginmanager
```
Но если что мы с тобой и так пройдем эти темы. А если хочешь прям догнать,то вот дополнительные ресурсы. Можем отдельно встречу организовать по вопросам::
https://victoriametrics.com/blog/go-sync-once/
https://dev.to/jones_charles_ad50858dbc0/a-developers-guide-to-synconce-your-go-concurrency-lifesaver-3kf2
https://backendinterview.ru/goLang/concurrency/sync.html

--------------------------------
# SYNC/POOL
## Оптимизация обработки строк с sync.Pool

### Описание задачи
В высоконагруженном сервисе частые аллокации буферов для преобразования строк создают нагрузку на GC.
Цель — реализовать оптимизированную функцию `ProcessString` с использованием `sync.Pool`, чтобы переиспользовать буферы `[]byte`.

### Требования
1. Функция `ProcessString(s string) string` преобразует строку в верхний регистр.
2. Использование `sync.Pool` для буферов `[]byte`.
3. Потокобезопасность, отсутствие утечек памяти.

```
Решение в ./syncpool/stringsupper
```



## Оптимизация HTTP-обработчика с sync.Pool

### Описание задачи
В высоконагруженных сервисах, обрабатывающих тысячи HTTP-запросов в секунду, частая аллокация объектов для декодирования JSON становится узким местом. Каждый вызов `json.NewDecoder` создает новый экземпляр `RequestData`, что приводит к:
- Высокой нагрузке на GC (сборщик мусора).
- Увеличению времени обработки запросов.
- Нестабильной работе при пиковых нагрузках.

**Цель:**  
Использовать `sync.Pool` для переиспользования объектов `RequestData`, сократив аллокации и улучшив производительность.

---

### Требования
1. **Реализация пула объектов**
    - Создать пул для структур `RequestData` с предварительной инициализацией вложенных полей (например, `map` или `slice`).
    - Гарантировать потокобезопасность.

2. **Метод `Reset()`**
    - Очистить все поля объекта перед возвратом в пул.
    - Для слайсов: сохранить базовый массив (`items = items[:0]`).
    - Для мап: явно удалить все ключи.

3. **Отсутствие утечек данных**
    - Убедиться, что объекты из пула не сохраняют данные предыдущих запросов.

```
Решение в ./syncpool/requestdata.go
```


## JSON-кэш с `sync.Pool` и `map + RWMutex`

### **Описание**
Этот проект демонстрирует **потокобезопасный JSON-кэш** с поддержкой TTL и оптимизированной сериализацией.  
Используется `sync.Pool` для **эффективной работы с JSON**, а также `map + RWMutex` для **более быстрого доступа к данным**.

---

### **Основные возможности**
- **Хранение объектов в `map` (с TTL)**
- **Автоматическое удаление устаревших объектов**
- **Быстрая сериализация JSON с `sync.Pool`**
- **Использование `sync.RWMutex` для конкурентного доступа**

---

### **Методы**
#### **Базовые операции**
- `Set(key string, value interface{})` – **добавить объект в кэш**
- `Get(key string) (interface{}, bool)` – **получить объект по ключу**
- `Delete(key string)` – **удалить объект**
- `ToJSON() ([]byte, error)` – **сериализовать кэш в JSON**

---

### **Как это работает?**
- Все объекты хранятся в **`map[string]item`** (ключ → объект с TTL).
- `sync.Pool` позволяет **переиспользовать JSON-буферы**, снижая нагрузку на GC.
- Очистка устаревших данных выполняется **в отдельной горутине**.  

```
Решение в ./syncpool/jsoncache.go
```


Но если что мы с тобой и так пройдем эти темы. А если хочешь прям догнать,то вот дополнительные ресурсы. Можем отдельно встречу организовать по вопросам::
https://ubiklab.net/posts/go-pool-and-mechanics-behind-it/
https://reliasoftware.com/blog/golang-sync-pool
https://dev.to/func25/go-syncpool-and-the-mechanics-behind-it-52c1
https://engineer.yadro.com/article/three-ways-to-optimize-memory-performance-on-go-with-memory-pools/
https://leapcell.io/blog/boost-go-performance-sync-pool
https://www.sobyte.net/post/2022-06/go-sync-pool/
https://goperf.dev/01-common-patterns/object-pooling/

--------------------

# SYNC/WAIT

# Задание: Синхронизация горутин с использованием `sync.WaitGroup`

**Цель задания**:  
Исправить код, чтобы все горутины корректно выводили значения от 0 до 99, и обеспечить завершение всех горутин перед выходом из программы.
```go
package main

import (
	"fmt"
	"sync"
)
func main() {
	cnt := 100
	wg := sync.WaitGroup{}
	wg.Add(cnt)
	for i := 0; i < cnt; i++ {
		go func(i int) {
			defer wg.Done()
			fmt.Println(i)
		}(i)
	}
	
	wg.Wait()
}
```


## Задание: Параллельные HTTP-запросы с синхронизацией через `sync.WaitGroup`

**Цель задания**:  
Исправить код так, чтобы основная горутина дожидалась завершения всех HTTP-запросов.
```go
package main

import (
	"fmt"
	"net/http"
	"time"
	"sync"
)

func fetchUrl(url string) error {
	_, err := http.Get(url)
	return err
}
func main() {
	urls := []string{
		"https://www.lamoda.ru",
		"https://www.yandex.ru",
		"https://www.mail.ru",
		"https://www.google.ru",
	}
	
	// добавим вайтгруппу
	wg := sync.WaitGroup{}
	for _, url := range urls {
		wg.Add(1)
		
		go func(url string) {
			defer wg.Done()
			
			fmt.Printf("Fetching %s....\n", url)
			err := fetchUrl(url)
			if err != nil {
				fmt.Printf("Error feaching %s: %v\n", url, err)
				return
			}
			fmt.Printf("Fetched %s\n", url)
		}(url)
	}
	fmt.Println("All request launched!")
	wg.Wait()
	fmt.Println("Program finished")
}

```


# Задание: Исправление синхронизации горутин 

**Цель задания**:  
Исправить код, чтобы основная горутина дожидалась завершения.
```go
package main

import (
	"context"
	"fmt"
	"time"
	"sync"
)

type logic struct{}

var Logic logic

func (l *logic) UpdateDB(ctx context.Context, item *Item) error {
	return nil // Заглушка
}

func (l *logic) FetchItems(ctx context.Context) ([]*Item, error) {
	return []*Item{
		{Value: 5},
		{Value: 15},
		{Value: 7},
	}, nil // Заглушка
}

type Item struct {
	Value int
}

func processItem(item *Item) {
	time.Sleep(time.Second)
	if item.Value > 10 {
		fmt.Printf("ERROR: item %d can't be more than 10\n", item.Value)
		return
	}

	err := Logic.UpdateDB(context.Background(), item)
	if err != nil {
		fmt.Println("ERROR: can't process item")
	}
}

func DoBusinessLogic() error {
	items, err := Logic.FetchItems(context.Background())
	if err != nil {
		return err
	}
	
	// синхронизировал вайтгруппой
	wg := sync.WaitGroup{}
	for _, item := range items {
		wg.Add(1)
		
		go func(){
			defer wg.Done()
			processItem(item)
		}()
	}
	
	wg.Wait()
	return nil
}

func main() {
	err := DoBusinessLogic()
	if err != nil {
		fmt.Println("Error:", err)
	}
	fmt.Println("All items processed")
}
```
https://dev.to/jpoly1219/waitgroups-in-go-3dkj
https://bytegoblin.io/blog/a-beginners-guide-to-waitgroups-in-go.mdx
https://www.golinuxcloud.com/golang-waitgroup/
https://habr.com/ru/articles/850018/